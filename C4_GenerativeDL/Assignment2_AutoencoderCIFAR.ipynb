{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Copy of C4W2_Assignment.ipynb","provenance":[{"file_id":"14YkkFDy93bTqcqLW3XRbzES7RqYHVHFE","timestamp":1610742470899}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"L6S2HVAkSt0p"},"source":["# Week 2 Assignment: CIFAR-10 Autoencoder\n","\n","For this week, you will create a convolutional autoencoder for the [CIFAR10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset. You are free to choose the architecture of your autoencoder provided that the output image has the same dimensions as the input image.\n","\n","After training, your model should meet loss and accuracy requirements when evaluated with the test dataset. You will then download the model and upload it in the classroom for grading. \n","\n","Let's begin!"]},{"cell_type":"markdown","metadata":{"id":"6r4iPr2jyisR"},"source":["***Important:*** *This colab notebook has read-only access so you won't be able to save your changes. If you want to save your work periodically, please click `File -> Save a Copy in Drive` to create a copy in your account, then work from there.*  "]},{"cell_type":"markdown","metadata":{"id":"g1mzy2J8_nc1"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"3EXwoz-KHtWO","executionInfo":{"status":"ok","timestamp":1610742517893,"user_tz":300,"elapsed":2398,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","from keras.models import Sequential"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n2Gs6Lyc_pd0"},"source":["## Load and prepare the dataset\n","\n","The [CIFAR 10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset already has train and test splits and you can use those in this exercise. Here are the general steps:\n","\n","* Load the train/test split from TFDS. Set `as_supervised` to `True` so it will be convenient to use the preprocessing function we provided.\n","* Normalize the pixel values to the range [0,1], then return `image, image` pairs for training instead of `image, label`. This is because you will check if the output image is successfully regenerated after going through your autoencoder.\n","* Shuffle and batch the train set. Batch the test set (no need to shuffle).\n"]},{"cell_type":"code","metadata":{"id":"t9F7YsCNIKSA","executionInfo":{"status":"ok","timestamp":1610745054364,"user_tz":300,"elapsed":433,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}}},"source":["# preprocessing function\n","def map_image(image, label):\n","  image = tf.cast(image, dtype=tf.float32)\n","  image = image / 255.0\n","\n","  return image, image # dataset label is not used. replaced with the same image input.\n","\n","# parameters\n","BATCH_SIZE = 128\n","SHUFFLE_BUFFER_SIZE = 1024\n","\n","\n","### START CODE HERE (Replace instances of `None` with your code) ###\n","\n","# use tfds.load() to fetch the 'train' split of CIFAR-10\n","train_dataset = tfds.load(\"cifar10\", as_supervised=True, split=\"train\")\n","# preprocess the dataset with the `map_image()` function above\n","train_dataset = train_dataset.map(map_image)\n","# shuffle and batch the dataset\n","train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","\n","# use tfds.load() to fetch the 'test' split of CIFAR-10\n","test_dataset = tfds.load(\"cifar10\", as_supervised=True, split=\"test\")\n","\n","# preprocess the dataset with the `map_image()` function above\n","test_dataset = test_dataset.map(map_image)\n","\n","# batch the dataset\n","test_dataset = test_dataset.batch(BATCH_SIZE)\n","\n","### END CODE HERE ###"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rPyOgGJs_t98"},"source":["## Build the Model\n","\n","Create the autoencoder model. As shown in the lectures, you will want to downsample the image in the encoder layers then upsample it in the decoder path. Note that the output layer should be the same dimensions as the original image. Your input images will have the shape `(32, 32, 3)`. If you deviate from this, your model may not be recognized by the grader and may fail. \n","\n","We included a few hints to use the Sequential API below but feel free to remove it and use the Functional API just like in the ungraded labs if you're more comfortable with it. Another reason to use the latter is if you want to visualize the encoder output. As shown in the ungraded labs, it will be easier to indicate multiple outputs with the Functional API. That is not required for this assignment though so you can just stack layers sequentially if you want a simpler solution."]},{"cell_type":"code","metadata":{"id":"Wr-Bok3lRgA3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610745466879,"user_tz":300,"elapsed":517,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}},"outputId":"53c37359-efe2-4cbe-9503-46b20cbf3485"},"source":["# suggested layers to use. feel free to add or remove as you see fit.\n","from keras.layers import Conv2D, UpSampling2D\n","\n","# use the Sequential API (you can remove if you want to use the Functional API)\n","\n","### START CODE HERE ###\n","# use `model.add()` to add layers (if using the Sequential API)\n","inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n","\n","# ENCODER\n","conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), \n","                               padding=\"same\", activation=\"relu\")(inputs)\n","max_pool_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv1)\n","\n","conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), \n","                               padding=\"same\", activation=\"relu\")(max_pool_1)\n","max_pool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv2)\n","\n","# Bottleneck\n","\n","bottle_neck = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), \n","                                     padding=\"same\", activation=\"relu\")(max_pool_2)\n","\n","# DECODER\n","\n","conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(bottle_neck)\n","upsample_1 = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(conv3)\n","\n","conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(upsample_1)\n","upsample_2 = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(conv4)\n","\n","conv5 = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), padding=\"same\", activation=\"sigmoid\")(upsample_2)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=conv5)\n","\n","### END CODE HERE ###\n","\n","model.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_9 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 8, 8, 128)         295040    \n","_________________________________________________________________\n","up_sampling2d_14 (UpSampling (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","up_sampling2d_15 (UpSampling (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 32, 32, 3)         1731      \n","=================================================================\n","Total params: 741,379\n","Trainable params: 741,379\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jRWTAijKEVUC"},"source":["## Configure training parameters\n","\n","We have already provided the optimizer, metrics, and loss in the code below."]},{"cell_type":"code","metadata":{"id":"iHIeD9eDETSk","executionInfo":{"status":"ok","timestamp":1610745469493,"user_tz":300,"elapsed":521,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}}},"source":["# Please do not change the model.compile() parameters\n","model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLQPhm1W_8dC"},"source":["## Training\n","\n","You can now use [model.fit()](https://keras.io/api/models/model_training_apis/#fit-method) to train your model. You will pass in the `train_dataset` and you are free to configure the other parameters. As with any training, you should see the loss generally going down and the accuracy going up with each epoch. If not, please revisit the previous sections to find possible bugs."]},{"cell_type":"code","metadata":{"id":"AMBimOnsRvg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610745485859,"user_tz":300,"elapsed":14836,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}},"outputId":"e8c22703-3a38-4376-f91b-47fe35f108f2"},"source":["# parameters\n","train_steps = len(train_dataset) // BATCH_SIZE \n","val_steps = len(test_dataset) // BATCH_SIZE\n","\n","### START CODE HERE ###\n","model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=val_steps, epochs=100)\n","### END CODE HERE ###"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","3/3 [==============================] - 1s 67ms/step - loss: 0.0626 - accuracy: 0.3642\n","Epoch 2/100\n","3/3 [==============================] - 0s 58ms/step - loss: 0.0596 - accuracy: 0.4611\n","Epoch 3/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0527 - accuracy: 0.4438\n","Epoch 4/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0437 - accuracy: 0.5416\n","Epoch 5/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0355 - accuracy: 0.5129\n","Epoch 6/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0334 - accuracy: 0.5090\n","Epoch 7/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0271 - accuracy: 0.4962\n","Epoch 8/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0236 - accuracy: 0.5146\n","Epoch 9/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0236 - accuracy: 0.5872\n","Epoch 10/100\n","3/3 [==============================] - 0s 104ms/step - loss: 0.0211 - accuracy: 0.5690\n","Epoch 11/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0192 - accuracy: 0.6123\n","Epoch 12/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0193 - accuracy: 0.5854\n","Epoch 13/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0174 - accuracy: 0.6088\n","Epoch 14/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0168 - accuracy: 0.6255\n","Epoch 15/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0153 - accuracy: 0.6423\n","Epoch 16/100\n","3/3 [==============================] - 0s 46ms/step - loss: 0.0152 - accuracy: 0.6178\n","Epoch 17/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0142 - accuracy: 0.6339\n","Epoch 18/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0132 - accuracy: 0.6523\n","Epoch 19/100\n","3/3 [==============================] - 0s 59ms/step - loss: 0.0129 - accuracy: 0.6696\n","Epoch 20/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0124 - accuracy: 0.6418\n","Epoch 21/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0120 - accuracy: 0.6239\n","Epoch 22/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0121 - accuracy: 0.6330\n","Epoch 23/100\n","3/3 [==============================] - 0s 46ms/step - loss: 0.0112 - accuracy: 0.6633\n","Epoch 24/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0105 - accuracy: 0.6540\n","Epoch 25/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0110 - accuracy: 0.6728\n","Epoch 26/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0106 - accuracy: 0.6554\n","Epoch 27/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0107 - accuracy: 0.6580\n","Epoch 28/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0104 - accuracy: 0.6912\n","Epoch 29/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0091 - accuracy: 0.7127\n","Epoch 30/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0092 - accuracy: 0.7222\n","Epoch 31/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0096 - accuracy: 0.7051\n","Epoch 32/100\n","3/3 [==============================] - 0s 54ms/step - loss: 0.0104 - accuracy: 0.7245\n","Epoch 33/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0090 - accuracy: 0.7441\n","Epoch 34/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0081 - accuracy: 0.7466\n","Epoch 35/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0086 - accuracy: 0.7327\n","Epoch 36/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0081 - accuracy: 0.7401\n","Epoch 37/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0075 - accuracy: 0.7401\n","Epoch 38/100\n","3/3 [==============================] - 0s 104ms/step - loss: 0.0080 - accuracy: 0.7242\n","Epoch 39/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0074 - accuracy: 0.7486\n","Epoch 40/100\n","3/3 [==============================] - 0s 46ms/step - loss: 0.0080 - accuracy: 0.7334\n","Epoch 41/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0084 - accuracy: 0.7590\n","Epoch 42/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.7332\n","Epoch 43/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0078 - accuracy: 0.7401\n","Epoch 44/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0073 - accuracy: 0.7633\n","Epoch 45/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0074 - accuracy: 0.7633\n","Epoch 46/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0073 - accuracy: 0.7583\n","Epoch 47/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0067 - accuracy: 0.7696\n","Epoch 48/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0073 - accuracy: 0.7507\n","Epoch 49/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0065 - accuracy: 0.7763\n","Epoch 50/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0065 - accuracy: 0.7608\n","Epoch 51/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0068 - accuracy: 0.7644\n","Epoch 52/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0062 - accuracy: 0.7759\n","Epoch 53/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0062 - accuracy: 0.7690\n","Epoch 54/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0061 - accuracy: 0.7529\n","Epoch 55/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0059 - accuracy: 0.7771\n","Epoch 56/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0063 - accuracy: 0.7670\n","Epoch 57/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0149 - accuracy: 0.7545\n","Epoch 58/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0123 - accuracy: 0.7415\n","Epoch 59/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0099 - accuracy: 0.7221\n","Epoch 60/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0101 - accuracy: 0.7364\n","Epoch 61/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0101 - accuracy: 0.7306\n","Epoch 62/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0089 - accuracy: 0.7036\n","Epoch 63/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0077 - accuracy: 0.7346\n","Epoch 64/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0078 - accuracy: 0.7402\n","Epoch 65/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0073 - accuracy: 0.7193\n","Epoch 66/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0068 - accuracy: 0.7496\n","Epoch 67/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0069 - accuracy: 0.7345\n","Epoch 68/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0066 - accuracy: 0.7609\n","Epoch 69/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0066 - accuracy: 0.7613\n","Epoch 70/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0064 - accuracy: 0.7575\n","Epoch 71/100\n","3/3 [==============================] - 0s 47ms/step - loss: 0.0062 - accuracy: 0.7676\n","Epoch 72/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0059 - accuracy: 0.7655\n","Epoch 73/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0059 - accuracy: 0.7863\n","Epoch 74/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0060 - accuracy: 0.7843\n","Epoch 75/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0057 - accuracy: 0.7796\n","Epoch 76/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0057 - accuracy: 0.7748\n","Epoch 77/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0059 - accuracy: 0.7517\n","Epoch 78/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0058 - accuracy: 0.7832\n","Epoch 79/100\n","3/3 [==============================] - 0s 56ms/step - loss: 0.0059 - accuracy: 0.7850\n","Epoch 80/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0056 - accuracy: 0.7880\n","Epoch 81/100\n","3/3 [==============================] - 0s 105ms/step - loss: 0.0054 - accuracy: 0.7766\n","Epoch 82/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0053 - accuracy: 0.7941\n","Epoch 83/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0057 - accuracy: 0.7750\n","Epoch 84/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0051 - accuracy: 0.7863\n","Epoch 85/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0055 - accuracy: 0.7681\n","Epoch 86/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0057 - accuracy: 0.7813\n","Epoch 87/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0058 - accuracy: 0.7875\n","Epoch 88/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0052 - accuracy: 0.7821\n","Epoch 89/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0053 - accuracy: 0.7921\n","Epoch 90/100\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0053 - accuracy: 0.7926\n","Epoch 91/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0052 - accuracy: 0.8055\n","Epoch 92/100\n","3/3 [==============================] - 0s 46ms/step - loss: 0.0054 - accuracy: 0.7857\n","Epoch 93/100\n","3/3 [==============================] - 0s 49ms/step - loss: 0.0051 - accuracy: 0.7826\n","Epoch 94/100\n","3/3 [==============================] - 0s 59ms/step - loss: 0.0057 - accuracy: 0.7824\n","Epoch 95/100\n","3/3 [==============================] - 0s 52ms/step - loss: 0.0071 - accuracy: 0.7802\n","Epoch 96/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0057 - accuracy: 0.7698\n","Epoch 97/100\n","3/3 [==============================] - 0s 51ms/step - loss: 0.0056 - accuracy: 0.7746\n","Epoch 98/100\n","3/3 [==============================] - 0s 50ms/step - loss: 0.0055 - accuracy: 0.7878\n","Epoch 99/100\n","3/3 [==============================] - 0s 48ms/step - loss: 0.0058 - accuracy: 0.7817\n","Epoch 100/100\n","3/3 [==============================] - 0s 45ms/step - loss: 0.0050 - accuracy: 0.7899\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f21954999b0>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"PT2l1c-SAaF4"},"source":["## Model evaluation\n","\n","You can use this code to test your model locally before uploading to the grader. To pass, your model needs to satisfy these two requirements:\n","\n","* loss must be less than 0.01 \n","* accuracy must be greater than 0.6"]},{"cell_type":"code","metadata":{"id":"vFncgqahSQhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610745492131,"user_tz":300,"elapsed":1169,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}},"outputId":"d4a8b7ed-19d8-47a6-a38f-56638756e106"},"source":["result = model.evaluate(test_dataset, steps=10)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["10/10 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 0.7819\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"di6VOHGwIsVM"},"source":["If you did some visualization like in the ungraded labs, then you might see something like the gallery below. This part is not required."]},{"cell_type":"markdown","metadata":{"id":"wmpI4skkIA5L"},"source":["<img src=\"https://drive.google.com/uc?export=view&id=12Fy-guiP-3tTPfc9IV2nHhqLvs7LwRo6\" width=\"75%\" height=\"75%\"/>"]},{"cell_type":"markdown","metadata":{"id":"uaRSkQPNAPT0"},"source":["## Save your model\n","\n","Once you are satisfied with the results, you can now save your model. Please download it from the Files window on the left and go back to the Submission portal in Coursera for grading."]},{"cell_type":"code","metadata":{"id":"pLFpLP-c7rDR","executionInfo":{"status":"ok","timestamp":1610745558508,"user_tz":300,"elapsed":662,"user":{"displayName":"Nicolás Roldán","photoUrl":"","userId":"15793920032108430403"}}},"source":["model.save('mymodel.h5')"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QArMiXJTDxDe"},"source":["**Congratulations on completing this week's assignment!**"]}]}